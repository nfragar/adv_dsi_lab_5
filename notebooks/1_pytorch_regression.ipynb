{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Regression with Pytorch\n",
    "\n",
    "In this exercise, we will build a Neural Networks with Pytorch for predicting pollution level. We will be working on the Beijing Pollution dataset:\n",
    "https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Beijing%20PM2.5\n",
    "\n",
    "The steps are:\n",
    "1.   Setup Repository\n",
    "2.   Load and Explore Dataset\n",
    "3.   Prepare Data\n",
    "4.   Baseline Model\n",
    "5.   Define Architecture\n",
    "6.   Create Data Loader\n",
    "7.   Train Model\n",
    "8.   Assess Performance\n",
    "9.   Push Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.0]** Change Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "cd /home/jovyan/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 20.04.4 LTS \\n \\l\r\n",
      "\r\n",
      "Ubuntu 20.04.4 LTS\r\n"
     ]
    }
   ],
   "source": [
    "! cat /etc/issue*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://software.intel.com/ipex-whl-stable\n",
      "\u001b[1;33mwarning\u001b[0m: \u001b[1mmissing-index-doctype\u001b[0m\n",
      "\n",
      "\u001b[33m×\u001b[0m The package index page being used does not have a proper HTML doctype declaration.\n",
      "\u001b[33m╰─>\u001b[0m Problematic URL: \u001b[4;94mhttps://www.intel.com/content/dam/develop/external/us/en/documents/ipex/whl-stable.html\u001b[0m\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the page at the URL mentioned above.\n",
      "\u001b[1;36mhint\u001b[0m: You might need to reach out to the owner of that package index, to get this fixed. See \u001b[4;94mhttps://github.com/pypa/pip/issues/10825\u001b[0m for context.\n",
      "Collecting intel_extension_for_pytorch==1.10.100\n",
      "  Downloading https://intel-optimized-pytorch.s3.cn-north-1.amazonaws.com.cn/wheels/v1.10/intel_extension_for_pytorch-1.10.100%2Bcpu-cp39-cp39-linux_x86_64.whl (103.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 MB\u001b[0m \u001b[31m959.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: intel_extension_for_pytorch\n",
      "Successfully installed intel_extension_for_pytorch-1.10.100+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install intel_extension_for_pytorch==1.10.100 -f https://software.intel.com/ipex-whl-stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.1]** Download the dataset into the `data/raw` folder:https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-07 10:37:45--  https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv\n",
      "Resolving code.datasciencedojo.com (code.datasciencedojo.com)... 167.99.111.153\n",
      "Connecting to code.datasciencedojo.com (code.datasciencedojo.com)|167.99.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1966669 (1.9M) [text/plain]\n",
      "Saving to: ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv’\n",
      "\n",
      "PRSA_data_2010.1.1- 100%[===================>]   1.88M  1.26MB/s    in 1.5s    \n",
      "\n",
      "2022-03-07 10:37:48 (1.26 MB/s) - ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv’ saved [1966669/1966669]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P data/raw https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.2]** Launch the magic commands for auto-relaoding external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Launch the magic commands for auto-relaoding external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.3]** Import the pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.4]** Load the data in a dataframe called `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw/PRSA_data_2010.1.1-2014.12.31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43824, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43824 entries, 0 to 43823\n",
      "Data columns (total 13 columns):\n",
      "No       43824 non-null int64\n",
      "year     43824 non-null int64\n",
      "month    43824 non-null int64\n",
      "day      43824 non-null int64\n",
      "hour     43824 non-null int64\n",
      "pm2.5    41757 non-null float64\n",
      "DEWP     43824 non-null int64\n",
      "TEMP     43824 non-null float64\n",
      "PRES     43824 non-null float64\n",
      "cbwd     43824 non-null object\n",
      "Iws      43824 non-null float64\n",
      "Is       43824 non-null int64\n",
      "Ir       43824 non-null int64\n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>6.523549</td>\n",
       "      <td>15.727820</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>98.613215</td>\n",
       "      <td>1.817246</td>\n",
       "      <td>12.448521</td>\n",
       "      <td>1016.447654</td>\n",
       "      <td>23.889140</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.194916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12651.043435</td>\n",
       "      <td>1.413842</td>\n",
       "      <td>3.448572</td>\n",
       "      <td>8.799425</td>\n",
       "      <td>6.922266</td>\n",
       "      <td>92.050387</td>\n",
       "      <td>14.433440</td>\n",
       "      <td>12.198613</td>\n",
       "      <td>10.268698</td>\n",
       "      <td>50.010635</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>1.415867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10956.750000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32868.250000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>585.600000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 No          year         month           day          hour  \\\n",
       "count  43824.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean   21912.500000   2012.000000      6.523549     15.727820     11.500000   \n",
       "std    12651.043435      1.413842      3.448572      8.799425      6.922266   \n",
       "min        1.000000   2010.000000      1.000000      1.000000      0.000000   \n",
       "25%    10956.750000   2011.000000      4.000000      8.000000      5.750000   \n",
       "50%    21912.500000   2012.000000      7.000000     16.000000     11.500000   \n",
       "75%    32868.250000   2013.000000     10.000000     23.000000     17.250000   \n",
       "max    43824.000000   2014.000000     12.000000     31.000000     23.000000   \n",
       "\n",
       "              pm2.5          DEWP          TEMP          PRES           Iws  \\\n",
       "count  41757.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean      98.613215      1.817246     12.448521   1016.447654     23.889140   \n",
       "std       92.050387     14.433440     12.198613     10.268698     50.010635   \n",
       "min        0.000000    -40.000000    -19.000000    991.000000      0.450000   \n",
       "25%       29.000000    -10.000000      2.000000   1008.000000      1.790000   \n",
       "50%       72.000000      2.000000     14.000000   1016.000000      5.370000   \n",
       "75%      137.000000     15.000000     23.000000   1025.000000     21.910000   \n",
       "max      994.000000     28.000000     42.000000   1046.000000    585.600000   \n",
       "\n",
       "                 Is            Ir  \n",
       "count  43824.000000  43824.000000  \n",
       "mean       0.052734      0.194916  \n",
       "std        0.760375      1.415867  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       27.000000     36.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Remove the column No as it is an identifier for rows\n",
    "df_cleaned.drop('No', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Remove the missing values from the target variable pm2.5\n",
    "df_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Reset the indexes of the dataframe\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import StandardScaler and OneHotEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a list called num_cols that contains year, DEWP, TEMP, PRES, Iws, Is, Ir\n",
    "num_cols = ['year', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Fit and transform the numeric feature of X_train_cleaned and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a list called cat_cols that contains Gender\n",
    "cat_cols = ['month', 'day', 'hour', 'cbwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a OneHotEncoder and called it ohe\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Perform One-Hot encoding on cat_cols and save them into a dataframe called X_cat\n",
    "X_cat = pd.DataFrame(ohe.fit_transform(df_cleaned[cat_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Task: Extract the feature names from ohe and replace the names of the columns of the X_cat\n",
    "X_cat.columns = ohe.get_feature_names(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Drop the original columns of cat_cols from df_cleaned\n",
    "df_cleaned.drop(cat_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Concatenate df_cleaned with X_cat and save the result to a variable called X\n",
    "X = pd.concat([df_cleaned, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "cd /home/jovyan/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import train_test_split from sklearn.model_selection\n",
    "from src.data.sets import split_sets_by_time, save_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(X, target_col='pm2.5', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/processed/beijing_pollution’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/processed/beijing_pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Save the sets in the data/processed/beijing_pollution folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='data/processed/beijing_pollution/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import NullModel from src.models.null\n",
    "from src.models.null import NullModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a NullModel and call .fit_predict() on the training target to extract your predictions into a variable called y_base\n",
    "base_model = NullModel(target_type=\"regression\")\n",
    "y_base = base_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.performance import print_reg_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Base: 92.82545840756482\n",
      "MAE Base: 69.67082209440568\n"
     ]
    }
   ],
   "source": [
    "print_reg_perf(y_base, y_train, set_name='Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5.2]** Create in `src/models/pytorch.py` a class called `PytorchRegression` that inherits from `nn.Module` with:\n",
    "- `num_features` as input parameter\n",
    "- attributes:\n",
    "    - `layer_1`: fully-connected layer with 128 neurons\n",
    "    - `layer_out`: fully-connected layer with 1 neurons\n",
    "- methods:\n",
    "    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a class called PytorchRegression that inherits from nn.Module\n",
    "class PytorchRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchRegression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 128)\n",
    "        self.layer_out = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)))\n",
    "        x = self.layer_out(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate PytorchRegression with the correct number of input feature and save it into a variable called model\n",
    "# from src.models.pytorch import PytorchRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchRegression(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchRegression(\n",
       "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchRegression(\n",
      "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Task: Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import Dataset and DataLoader from torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a class called PytorchDataset\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Convert all numpy array sets to PytorchDataset\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a nn.MSELoss() and save it into a variable called criterion\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called `train_regression()` that will perform forward and back propagation and \n",
    "# calculate loss and RMSE scores\n",
    "\n",
    "def train_regression(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, collate_fn=None):\n",
    "    \"\"\"Train a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class)\n",
    "        \n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), np.sqrt(train_loss / len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a function called `test_regression()` that will perform forward and calculate loss and RMSE scores\n",
    "\n",
    "def test_regression(test_data, model, criterion, batch_size, device, collate_fn=None):\n",
    "    \"\"\"Calculate performance of a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class)\n",
    "            \n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    return test_loss / len(test_data), np.sqrt(test_loss / len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 5 and 32 as values\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 272.1585\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 236.9672\t|\tRMSE: 15.4\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 272.1389\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.1508\t|\tRMSE: 15.4\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 272.0000\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.7895\t|\tRMSE: 15.4\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 272.2039\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.1903\t|\tRMSE: 15.4\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 271.8850\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.0916\t|\tRMSE: 15.4\n"
     ]
    }
   ],
   "source": [
    "# Task: Create a for loop that will iterate through the specified number of epochs and \n",
    "# will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_rmse = train_regression(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_rmse = test_regression(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tRMSE: {train_rmse:.1f}')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tRMSE: {valid_rmse:.1f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Save the model into the models folder\n",
    "torch.save(model, \"models/pytorch_reg_pm2_5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.   Assess Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 276.4204\t|\tRMSE: 16.6\n"
     ]
    }
   ],
   "source": [
    "# Task: Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_rmse = test_regression(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tRMSE: {test_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pytorch_reg 03b60a8] pytorch regression\n",
      " 23 files changed, 4386 insertions(+), 1004 deletions(-)\n",
      " create mode 100644 models/pytorch_reg_pm2_5.pt\n",
      " create mode 100644 notebooks/1_pytorch_regression.ipynb\n",
      " create mode 100644 notebooks/Group1-Assignment1-LogisticRegression.ipynb\n",
      " create mode 100644 src/data/sets.py\n",
      " create mode 100644 src/models/null.py\n",
      " create mode 100644 src/models/performance.py\n",
      " create mode 100644 src/models/pytorch.py\n"
     ]
    }
   ],
   "source": [
    "# Task: Add Changes to GIT\n",
    "! git add .\n",
    "! git commit -m \"pytorch regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --global user.email \"nathan@fragar.id.au\"\n",
    "! git config --global user.name \"Nathan Fragar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: src refspec origin does not match any\r\n",
      "\u001b[31merror: failed to push some refs to 'upstream'\r\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "! git push --set upstream origin pytorch_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

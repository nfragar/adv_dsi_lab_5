{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Multi-Class Classification with Pytorch\n",
    "\n",
    "In this exercise, we will build a a Neural Networks with Pytorch for predicting car evaluation. We will be woking on the Car dataset:\n",
    "https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv\n",
    "\n",
    "\n",
    "The steps are:\n",
    "1.   Setup Repository\n",
    "2.   Load and Explore Dataset\n",
    "3.   Prepare Data\n",
    "4.   Baseline Model\n",
    "5.   Define Architecture\n",
    "6.   Train Model\n",
    "7.   Push Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: adv_dsi_lab_5: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Task: Go inside the created folder adv_dsi_lab_5\n",
    "! cd adv_dsi_lab_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "cd /home/jovyan/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'pytorch_multi_class'\r\n"
     ]
    }
   ],
   "source": [
    "# Task: Create a new git branch called pytorch_multi_class\n",
    "! git checkout -b pytorch_multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.0]** Change Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "cd /home/jovyan/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 20.04.4 LTS \\n \\l\r\n",
      "\r\n",
      "Ubuntu 20.04.4 LTS\r\n"
     ]
    }
   ],
   "source": [
    "! cat /etc/issue*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.1]** Download the dataset into the `data/raw` folder:https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-08 09:08:03--  https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 53678 (52K) [text/plain]\n",
      "Saving to: ‘data/raw/Car Evaluation.csv’\n",
      "\n",
      "Car Evaluation.csv  100%[===================>]  52.42K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2022-03-08 09:08:03 (4.70 MB/s) - ‘data/raw/Car Evaluation.csv’ saved [53678/53678]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P data/raw https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.2]** Launch the magic commands for auto-relaoding external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Launch the magic commands for auto-relaoding external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.3]** Import the pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.4]** Load the data in a dataframe called `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw/Car Evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying_price maintenance_cost doors persons_capacity luggage_boot safety  \\\n",
       "0        vhigh            vhigh     2                2        small    low   \n",
       "1        vhigh            vhigh     2                2        small    med   \n",
       "2        vhigh            vhigh     2                2        small   high   \n",
       "3        vhigh            vhigh     2                2          med    low   \n",
       "4        vhigh            vhigh     2                2          med    med   \n",
       "\n",
       "  evaluation  \n",
       "0      unacc  \n",
       "1      unacc  \n",
       "2      unacc  \n",
       "3      unacc  \n",
       "4      unacc  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   buying_price      1728 non-null   object\n",
      " 1   maintenance_cost  1728 non-null   object\n",
      " 2   doors             1728 non-null   object\n",
      " 3   persons_capacity  1728 non-null   object\n",
      " 4   luggage_boot      1728 non-null   object\n",
      " 5   safety            1728 non-null   object\n",
      " 6   evaluation        1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying_price maintenance_cost doors persons_capacity luggage_boot  \\\n",
       "count          1728             1728  1728             1728         1728   \n",
       "unique            4                4     4                3            3   \n",
       "top           vhigh            vhigh     2                2        small   \n",
       "freq            432              432   432              576          576   \n",
       "\n",
       "       safety evaluation  \n",
       "count    1728       1728  \n",
       "unique      3          4  \n",
       "top       low      unacc  \n",
       "freq      576       1210  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe locally in the data/raw folder\n",
    "df.to_csv('data/raw/car_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a copy of df and save it into a variable called df_cleaned\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a dictionary called cats_dict that contains the categorical variables as keys and their respective values \n",
    "# sorted in ascending order\n",
    "cats_dict = {\n",
    "    'buying_price': [['low', 'med', 'high', 'vhigh']],\n",
    "    'maintenance_cost': [['low', 'med', 'high', 'vhigh']],\n",
    "    'doors': [['2', '3', '4', '5more']],\n",
    "    'persons_capacity': [['2', '4', 'more']],\n",
    "    'luggage_boot': [['small', 'med', 'big']],\n",
    "    'safety': [['low', 'med', 'high']],\n",
    "    'evaluation': [['unacc', 'acc', 'good', 'vgood']],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import StandardScaler and OrdinalEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Iterate through the elements of cast_dict, instantiate an OrdinalEncoder() and \n",
    "# transform the values of each column with this encoder\n",
    "\n",
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_price  maintenance_cost  doors  persons_capacity  luggage_boot  \\\n",
       "0           3.0               3.0    0.0               0.0           0.0   \n",
       "1           3.0               3.0    0.0               0.0           0.0   \n",
       "2           3.0               3.0    0.0               0.0           0.0   \n",
       "3           3.0               3.0    0.0               0.0           1.0   \n",
       "4           3.0               3.0    0.0               0.0           1.0   \n",
       "\n",
       "   safety  evaluation  \n",
       "0     0.0         0.0  \n",
       "1     1.0         0.0  \n",
       "2     2.0         0.0  \n",
       "3     0.0         0.0  \n",
       "4     1.0         0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a list called num_cols that contains all numeric columns\n",
    "num_cols = ['buying_price', 'maintenance_cost', 'doors', 'persons_capacity', 'luggage_boot', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a StandardScaler and called it sc\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Fit and transform the numeric feature of X_train_cleaned and replace the data into it\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['evaluation'] = df_cleaned['evaluation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_price  maintenance_cost     doors  persons_capacity  luggage_boot  \\\n",
       "0      1.341641          1.341641 -1.341641         -1.224745     -1.224745   \n",
       "1      1.341641          1.341641 -1.341641         -1.224745     -1.224745   \n",
       "2      1.341641          1.341641 -1.341641         -1.224745     -1.224745   \n",
       "3      1.341641          1.341641 -1.341641         -1.224745      0.000000   \n",
       "4      1.341641          1.341641 -1.341641         -1.224745      0.000000   \n",
       "\n",
       "     safety  evaluation  \n",
       "0 -1.224745           0  \n",
       "1  0.000000           0  \n",
       "2  1.224745           0  \n",
       "3 -1.224745           0  \n",
       "4  0.000000           0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import train_test_split from sklearn.model_selection\n",
    "from src.data.sets import split_sets_random, save_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Split the data into training and testing sets with 80-20 ratio\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned, target_col='evaluation', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data/processed/car_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Save the sets in the data/processed/credit_card_default folder\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='data/processed/car_evaluation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import NullModel from src.models.null\n",
    "from src.models.null import NullModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a NullModel and call .fit_predict() on the training target to extract your predictions into a variable called y_base\n",
    "base_model = NullModel(target_type=\"classification\")\n",
    "y_base = base_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.performance import print_class_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.6988416988416989\n",
      "F1 Training: 0.5749561249561249\n"
     ]
    }
   ],
   "source": [
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import torch and torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5.2]** Create in `src/models/pytorch.py` a class called `PytorchMultiClass` that inherits from `nn.Module` with:\n",
    "- `num_features` as input parameter\n",
    "- attributes:\n",
    "    - `layer_1`: fully-connected layer with 32 neurons\n",
    "    - `layer_out`: fully-connected layer with 4 neurons\n",
    "    - `softmax`: softmax function\n",
    "- methods:\n",
    "    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a class called PytorchMultiClass that inherits from nn.Module\n",
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate PytorchMultiClass with the correct number of input feature and save it into a variable called model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
      "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Task: Print the architecture of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Import Dataset and DataLoader from torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a class called PytorchDataset\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Convert all numpy array sets to PytorchDataset\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a nn.CrossEntropyLoss() and save it into a variable called criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a torch.optim.Adam() optimizer with the model's parameters and 0.1 as learning rate and save it into a variable called optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Instantiate a torch.optim.lr_scheduler.StepLR() scheduler that will decrease the learning rate by a coefficient of 0.9 for each epoch\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called `train_classification()` that will perform forward and back propagation and\n",
    "# calculate loss and Accuracy scores\n",
    "\n",
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a function called `test_classification()` that will perform forward and calculate loss and accuracy scores\n",
    "\n",
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 5 and 32 as values\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.0322\t|\tAcc: 73.4%\n",
      "\t(valid)\t|\tLoss: 0.0296\t|\tAcc: 80.6%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.0307\t|\tAcc: 77.6%\n",
      "\t(valid)\t|\tLoss: 0.0294\t|\tAcc: 81.8%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.0300\t|\tAcc: 79.6%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.1%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.3%\n",
      "\t(valid)\t|\tLoss: 0.0285\t|\tAcc: 84.4%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.0%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.1%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0283\t|\tAcc: 85.0%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 82.7%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.7%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 82.4%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 83.4%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.4%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 87.6%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.0288\t|\tAcc: 83.6%\n",
      "\t(valid)\t|\tLoss: 0.0281\t|\tAcc: 86.1%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.6%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 85.7%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.7%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.1%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.5%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.7%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.5%\n",
      "\t(valid)\t|\tLoss: 0.0272\t|\tAcc: 89.0%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 85.1%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.4%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.7%\n",
      "Epoch: 20\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.7%\n",
      "\t(valid)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "Epoch: 21\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 84.7%\n",
      "\t(valid)\t|\tLoss: 0.0283\t|\tAcc: 85.0%\n",
      "Epoch: 22\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 82.5%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 23\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 85.1%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.0%\n",
      "Epoch: 24\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "\t(valid)\t|\tLoss: 0.0270\t|\tAcc: 89.6%\n",
      "Epoch: 25\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.8%\n",
      "\t(valid)\t|\tLoss: 0.0271\t|\tAcc: 89.0%\n",
      "Epoch: 26\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.9%\n",
      "\t(valid)\t|\tLoss: 0.0272\t|\tAcc: 89.0%\n",
      "Epoch: 27\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 28\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.6%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 29\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.9%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 30\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.9%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.2%\n",
      "Epoch: 31\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.3%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "Epoch: 32\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.2%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 33\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 85.2%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.4%\n",
      "Epoch: 34\n",
      "\t(train)\t|\tLoss: 0.0281\t|\tAcc: 86.1%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 35\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 85.4%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.1%\n",
      "Epoch: 36\n",
      "\t(train)\t|\tLoss: 0.0280\t|\tAcc: 86.3%\n",
      "\t(valid)\t|\tLoss: 0.0285\t|\tAcc: 84.7%\n",
      "Epoch: 37\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.7%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 87.9%\n",
      "Epoch: 38\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 86.9%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 39\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.0%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.1%\n",
      "Epoch: 40\n",
      "\t(train)\t|\tLoss: 0.0276\t|\tAcc: 87.5%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 85.0%\n",
      "Epoch: 41\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 85.9%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 42\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.2%\n",
      "\t(valid)\t|\tLoss: 0.0272\t|\tAcc: 88.7%\n",
      "Epoch: 43\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.4%\n",
      "Epoch: 44\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.1%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.2%\n",
      "Epoch: 45\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "\t(valid)\t|\tLoss: 0.0275\t|\tAcc: 88.2%\n",
      "Epoch: 46\n",
      "\t(train)\t|\tLoss: 0.0278\t|\tAcc: 87.1%\n",
      "\t(valid)\t|\tLoss: 0.0274\t|\tAcc: 88.2%\n",
      "Epoch: 47\n",
      "\t(train)\t|\tLoss: 0.0277\t|\tAcc: 87.6%\n",
      "\t(valid)\t|\tLoss: 0.0271\t|\tAcc: 88.7%\n",
      "Epoch: 48\n",
      "\t(train)\t|\tLoss: 0.0274\t|\tAcc: 88.1%\n",
      "\t(valid)\t|\tLoss: 0.0273\t|\tAcc: 88.4%\n",
      "Epoch: 49\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.5%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n"
     ]
    }
   ],
   "source": [
    "# Task: Create a for loop that will iterate through the specified number of epochs and \n",
    "# will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Save the model into the models folder\n",
    "torch.save(model, \"models/pytorch_multi_car_evaluation.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.   Assess Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.0288\t|\tAccuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Task: Assess the model performance on the testing set and print its scores\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 9e62c9d] pytorch binary classification\r\n",
      " 4 files changed, 3010 insertions(+), 1409 deletions(-)\r\n",
      " create mode 100644 models/pytorch_bin_default_card.pt\r\n",
      " create mode 100644 notebooks/2_pytorch_binary_classification.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# Task: Add Changes to GIT\n",
    "! git add .\n",
    "! git commit -m \"pytorch binary classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --global user.email \"nathan@fragar.id.au\"\n",
    "! git config --global user.name \"Nathan Fragar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: src refspec origin does not match any\r\n",
      "\u001b[31merror: failed to push some refs to 'upstream'\r\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "! git push --set upstream origin pytorch_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
